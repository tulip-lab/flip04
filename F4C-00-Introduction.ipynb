{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLIP (04): Learning Theory (I)\n",
    "**(Module 03: Convex Optimization)**\n",
    "\n",
    "---\n",
    "- Materials in this module include resources collected from various open-source online repositories.\n",
    "- You are free to use, but NOT allowed to change or distribute this package.\n",
    "\n",
    "Prepared by and for \n",
    "**Student Members** |\n",
    "2006-2018 [TULIP Lab](http://www.tulip.org.au), Australia\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mathematical optimization**, traditionally also known as mathematical programming, is the theory of optimal decision making. Optimization problems arise in a large variety of contexts, including **scheduling and logistics**, **finance**, **optimal control**, **signal processing**, and **machine learning**. The underlying mathematical problem always amounts to finding parameters that **minimize** (cost) or **maximize** (utility) an objective function in the presence or absence of a set of constraints.\n",
    "An important special case is the class of **convex optimization** problems. Such problems will be the main focus of this course.\n",
    "$\\newcommand{\\vct}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\mtx}[1]{\\mathbf{#1}}$\n",
    "$\\newcommand{\\e}{\\varepsilon}$\n",
    "$\\newcommand{\\norm}[1]{\\|#1\\|}$\n",
    "$\\newcommand{\\minimize}{\\text{minimize}\\quad}$\n",
    "$\\newcommand{\\maximize}{\\text{maximize}\\quad}$\n",
    "$\\newcommand{\\subjto}{\\quad\\text{subject to}\\quad}$\n",
    "$\\newcommand{\\R}{\\mathbb{R}}$\n",
    "$\\newcommand{\\trans}{T}$\n",
    "$\\newcommand{\\ip}[2]{\\langle {#1}, {#2} \\rangle}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### What is an optimization problem?</font>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general mathematical optimization problem is a problem of the form\n",
    "\n",
    "\\begin{align*}\n",
    "\\begin{split}\n",
    " \\minimize & f(\\vct{x})\\\\\n",
    " \\subjto & \\vct{x}\\in \\Omega\n",
    " \\end{split}\n",
    "\\end{align*}\n",
    "\n",
    "where $f\\colon \\R^n\\to \\R$ is a real-valued **objective function** and $\\Omega\\subseteq \\R^n$ is a set defining the **constraints**. Among all vectors $\\vct{x}\\in \\Omega$, we seek one with smallest $f$-value. Typically, the constraint set $\\Omega$ will consist of such $\\vct{x}\\in \\R^n$ that satisfy certain equations and inequalities,\n",
    "\n",
    "\\begin{equation*}\n",
    "f_1(\\vct{x})\\leq 0, \\dots, f_m(\\vct{x})\\leq 0, g_1(\\vct{x})=0, \\dots, g_p(\\vct{x})=0.\n",
    "\\end{equation*}\n",
    "\n",
    "A vector $\\vct{x}^*$ satisfying the constraints is called an **optimum**, a **solution**, or a **minimizer** of the problem, if $f(\\vct{x}^*)\\leq f(\\vct{x})$ for all other $\\vct{x}\\in \\Omega$. Note that replacing $f$ by $-f$, we could equivalently state the problem as a maximization problem. In this course we are mostly concerned with functions and constraint sets that are **convex**.\n",
    "\n",
    "* A set $C\\subseteq \\R^n$ is **convex**, if for all $\\vct{x},\\vct{y}\\in C$ and $\\lambda\\in [0,1]$, $\\lambda \\vct{x}+(1-\\lambda)\\vct{y}\\in C$. That is, if for any two points in $C$, the line segment connecting them is also in $C$. \n",
    "* A function $f\\colon C\\to \\R$ is convex, if $C$ is convex and for all $\\vct{x}\\in C$ and $\\lambda\\in [0,1]$, $f(\\lambda \\vct{x}+(1-\\lambda)\\vct{y})\\leq \\lambda f(\\vct{x})+(1-\\lambda)f(\\vct{y})$. \n",
    "\n",
    "\n",
    "A **convex optimization** problem is one where the set of constraints $\\Omega$ and the function $f$ are convex. While most general optimization problems are practically intractable, convex optimization problems can be solved efficiently, and still cover a surprisingly large range of applications!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Examples of convex optimization problems</font>\n",
    "---\n",
    "Countless problems from science and engineering can be cast as convex optimization problems. We present a few first examples, many more will follow in the course of this lecture. The examples below come with associated Python code. At this moment it is not expected that you understand them in detail, they are merely intended to illustrate some of the problems that convex optimization deals with, and how they can be solved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first example: linear regression\n",
    "\n",
    "Suppose we want to understand the relationship of a quantity $Y$ (for example, sales data) to a series of **predictors** $X_1,\\dots,X_p$ (for example, advertising budget in different media). We can often assume the relationship to be **approximately linear**,\n",
    "\n",
    "[1]\\begin{equation*}\n",
    " Y = \\beta_0+\\beta_1 X_1 + \\cdots + \\beta_p X_p + \\varepsilon, \n",
    "\\end{equation*}\n",
    "\n",
    "where $\\varepsilon$ is some error or noise term. The goal is to determine the **model parameters** $\\beta_0,\\dots,\\beta_p$.\n",
    "To determine these, we can collect $n\\geq p$ sample realizations (from observations or experiments),\n",
    "\n",
    "\\begin{equation*}\n",
    " Y=y_i, \\quad X_1=x_{i1},\\dots,X_p=x_{ip}, \\quad 1\\leq i\\leq n,\n",
    "\\end{equation*}\n",
    "\n",
    "and assume that the data is related according to [1], \n",
    "\n",
    "\\begin{equation*}\n",
    " y_i = \\beta_0+\\beta_1x_{i1}+\\cdots +\\beta_p x_{ip}+\\varepsilon_i, \\quad 1\\leq i\\leq n.\n",
    "\\end{equation*}\n",
    "\n",
    "Collecting the data in matrices and vectors,\n",
    "\n",
    "\\begin{equation*}\n",
    " \\vct{y} = \\begin{pmatrix}\n",
    "            y_1\\\\ \\vdots \\\\ y_n\n",
    "           \\end{pmatrix},\n",
    "\\quad \\mtx{X} = \\begin{pmatrix} \n",
    "           1 & x_{11} & \\cdots & x_{1p}\\\\\n",
    "           \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "           1 & x_{n1} & \\cdots & x_{np}\n",
    "          \\end{pmatrix},\n",
    "\\quad \\vct{\\beta} = \\begin{pmatrix}\n",
    "                     \\beta_0\\\\\n",
    "                     \\beta_1\\\\\n",
    "                     \\vdots\\\\\n",
    "                     \\beta_p\n",
    "                    \\end{pmatrix},\n",
    "\\quad \\vct{\\varepsilon} = \\begin{pmatrix}\n",
    "                  \\e_1\\\\\n",
    "                  \\vdots\\\\\n",
    "                  \\e_n\n",
    "                 \\end{pmatrix},\n",
    "\\end{equation*}\n",
    "\n",
    "we can write the relationship concisely as \n",
    "\n",
    "\\begin{equation*}\n",
    " \\vct{y} = \\mtx{X}\\vct{\\beta}+\\vct{\\e}.\n",
    "\\end{equation*}\n",
    "\n",
    "We would then like to find $\\vct{\\beta}$ in such a way that the difference $\\vct{\\e}=\\vct{y}-\\mtx{X}\\vct{\\beta}$ is as *small* as possible. One way of measuring the size of a vector $\\vct{x}\\in \\R^n$ is the square of its **$2$-norm**, or Euclidean norm, \n",
    "\n",
    "\\begin{equation*}\n",
    " \\norm{\\vct{x}}_2^2=\\vct{x}^{T}\\vct{x}=\\sum_{i=1}^nx_i^2.\n",
    "\\end{equation*}\n",
    "\n",
    "The best $\\vct{\\beta}$ is then the vector that solves the unconstrained optimization problem\n",
    "\n",
    "\\begin{equation*}\n",
    " \\minimize \\norm{\\mtx{X}\\vct{\\beta}-\\vct{y}}_2^2.\n",
    "\\end{equation*}\n",
    "\n",
    "This is an example of an optimization problem, with variables $\\vct{\\beta}$, no constraints (*all* $\\beta$ are valid candidates and the constraint set is $\\Omega=\\R^{p+1}$), and a **quadratic** objective function \n",
    "\n",
    "\\begin{equation*}\n",
    "f(\\vct{\\beta})=\\norm{\\mtx{X}\\vct{\\beta}-\\vct{y}}_2^2 = (\\mtx{X}\\vct{\\beta}-\\vct{y})^{T}(\\mtx{X}\\vct{\\beta}-\\vct{y}) = \\vct{\\beta}^{T}\\mtx{X}^{T}\\mtx{X}\\vct{\\beta}-2\\vct{y}^{T}\\mtx{X}\\vct{\\beta}+\\vct{y}^{T}\\vct{y},\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\mtx{X}^{T}$ is the matrix transpose.\n",
    "As we will see later, quadratic functions are convex, so this is a convex optimization problem.\n",
    "This simple optimization problem has a **unique closed form solution**,\n",
    "\n",
    "\\begin{equation*}\n",
    " \\vct{\\beta}^* = (\\vct{X}^{\\trans}\\vct{X})^{-1}\\vct{X}^{\\trans}\\vct{y}.\n",
    "\\end{equation*}\n",
    "\n",
    "In practice one wouldn't compute $\\vct{\\beta}^*$ by evaluating [1], as there are more efficient methods available (see Lecture 2). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate the least squares setting using a concrete example, assume that we have data relating the basal metabolic rate (energy expenditure per time unit) in mammals to their mass (this example is from the episode ``[Size Matters](http://www.bbc.co.uk/programmes/b01qygxz)'' of the BBC series Wonders of Life.)\n",
    "\n",
    "\n",
    "The model we use is $Y=\\beta_0+\\beta_1X$, with $Y$ the basal metabolic rate and $X$ the mass. Using data for 573 mammals from the [PanTHERIA database](http://esapubs.org/archive/ecol/E090/184/\\#data), we can assemble the vector $\\vct{y}$ and the matrix $\\mtx{X}\\in \\R^{n\\times (p+1)}$ in order to compute the $\\vct{\\beta}=(\\beta_0,\\beta_1)^{\\trans}$. Here, $p=1$ and $n=573$.\n",
    "\n",
    "We next illustrate how to solve this problem in Python. As usual, we first have to import some relevant libraries: **numpy** for numerical computation, **pandas** for loading and transforming datasets, **cvxpy** for convex optimization, and **matplotlib** for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import some important Python modules that we will be using in this notebook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cvxpy import *\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next have to load the data. The data is saved in a table with 573 rows and 2 columns, where the first column list the mass and the second the basal metabolic rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data into numpy array\n",
    "bmr = pd.read_csv('data/bmr.csv',header=None).as_matrix()\n",
    "# We can find out the dimension of the data using the shape attribute\n",
    "bmr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the first three and the last three rows of the dataset, we can use the \"print\" command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(bmr[0:3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the whole dataset, we can make a scatterplot by interpreting each row as a coordinate on the plane, and marking it with a dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display scatterplot of data (plot all the rows as points on the plane)\n",
    "% matplotlib inline\n",
    "bmr1 = plt.plot(bmr[:,0],bmr[:,1],'o')\n",
    "plt.xlabel(\"Mass\")\n",
    "plt.ylabel(\"Basal metabolic rate\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above suggests that the relation of the basal metabolic rate to the mass is linear, i.e., of the form\n",
    "\\begin{equation*}\n",
    "  Y = \\beta_0+\\beta_1 X,\n",
    "\\end{equation*}\n",
    "where X is the mass and Y the BMR. We can find $\\beta_0$ and $\\beta_1$ by solving an optimization problem as described above. We first have to assemble the matrix $\\mtx{X}$ and the vector $\\vct{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = bmr.shape[0]\n",
    "p = 1\n",
    "X = np.concatenate((np.ones((n,1)),bmr[:,0:p]),axis=1)\n",
    "y = bmr[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a (p+1) vector of variables\n",
    "Beta = Variable(p+1)\n",
    "\n",
    "# Create sum-of-squares objective function\n",
    "objective = Minimize(sum_entries(square(X*Beta - y)))\n",
    "\n",
    "# Create problem and solve it\n",
    "prob = Problem(objective)\n",
    "prob.solve()\n",
    "\n",
    "print(\"status: \", prob.status)\n",
    "print(\"optimal value: \", prob.value)\n",
    "print(\"optimal variables: \", Beta[0].value, Beta[1].value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we solved the problem and have the values $\\beta_0 = 1.362$ and $\\beta_1 = 0.702$, we can plot the line and see how it fits the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(bmr[:,0],bmr[:,1],'o')\n",
    "\n",
    "xx = np.linspace(0,14,100)\n",
    "bmr = plt.plot(xx, Beta[0].value+Beta[1].value*xx, color='red', linewidth=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Even though for illustration purposes we used the CVXPY package, this particular problem can be solved directly using the least squares solver in numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy.linalg as la\n",
    "beta = la.lstsq(X,y)\n",
    "print(beta[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning</font>\n",
    "---\n",
    "\n",
    "The above example is an example of a **machine learning** problem. In machine learning, one seeks to **learn** a function $F$ mapping some inputs $X$ to outputs $Y$, $Y=F(X)$. A few examples:\n",
    "* X: economic data, Y: value of a stock;\n",
    "* X: physiological data, Y: medical diagnosis;\n",
    "* X: email, Y: 1 if email is span, 0 otherwise;\n",
    "* X: scanned image, Y: a letter represented by that image.\n",
    "\n",
    "In **supervised learning** we have a set of sample input pairs, $(y_i,x_i)$, $1\\leq i\\leq m$, and we typically try to find a function $F$ that minimizes the **least squared error**,\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\minimize \\sum_{i=1}^m (\\vct{y}_i-F(\\vct{x}_i))^2,\n",
    "\\end{equation*}\n",
    "\n",
    "where one minimizes over all functions $F$ from some class. In the above example, we assumed our functions to be linear, in which case the can by parametrized by the coefficients $\\beta_0, \\dots,\\beta_p$. As the course progresses, we will see examples of more sophisticated machine learning problems, often with nonlinear objective function and other **loss functions** instead of the least square error. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A second example: linear programming</font>\n",
    "---\n",
    "Suppose a plane has two cargo compartments with weight capacities $C_1=35$ and $C_2=40$ tonnes, and volumes (space capacities) $V_1=250$ and $V_2=400$ cubic metres. Assume we have three types of cargo to transport, specified as follows.\n",
    " \n",
    " |          | Volume (m$^3$ per tonne) | Weight (tonnes) | Profit (£ / tonne)|\n",
    " |---------:|--------------------------|-----------------|-------------------------| \n",
    " | Cargo 1  |   8                      |  25             | £ 300           |\n",
    " | Cargo 2  |  10                      |  32             | £ 350           |\n",
    " | Cargo 3  |   7                      |  28             | £ 270           |\n",
    "  \n",
    " The problem is now to decide how much of each cargo to take on board, and how to distribute it in an optimal way among the two compartments.\n",
    " 1. The **decision variables** $x_{ij}$ specify the amount, in tonnes, of cargo $i$ to go into compartment $j$. We collect them in a vector $\\vct{x}$.\n",
    " 2. The **objective function** is the total profit, \n",
    " \n",
    "  \\begin{equation*}\n",
    "   f(\\vct{x}) = 300\\cdot (x_{11}+x_{12})+ 350\\cdot (x_{21}+x_{22})+270\\cdot (x_{31}+x_{32}).\n",
    "  \\end{equation*}\n",
    " \n",
    " \n",
    " 3. The **constraints** are given by the space and weight limitations of the compartments, and the amount of cargo available.\n",
    "\n",
    "\\begin{align*}\n",
    " x_{11}+x_{12} & \\leq 25 \\quad \\text{ (total amount of cargo 1)}\\\\ \n",
    " x_{21}+x_{22} & \\leq 32 \\quad \\text{ (total amount of cargo 2)}\\\\ \n",
    " x_{31}+x_{32} & \\leq 28 \\quad \\text{ (total amount of cargo 3)}\\\\\n",
    " x_{11}+x_{21}+x_{31} & \\leq 35 \\quad \\text{ (weight constraint on compartment 1)}\\\\\n",
    " x_{12}+x_{22}+x_{32} & \\leq 40 \\quad \\text{ (weight constraint on compartment 2)}\\\\\n",
    " 8x_{11}+10x_{21}+7x_{31} & \\leq 250 \\quad \\text{ (volume constraint on compartment 1)}\\\\\n",
    " 8x_{12}+10x_{22}+7x_{32} & \\leq 400 \\quad \\text{ (volume constraint on compartment 2)}\\\\\n",
    " (x_{11}+x_{21}+x_{31})/35 - (x_{12}+x_{22}+x_{32})/40 &= 0 \\quad \\text{ (maintain balance of weight ratio)}\\\\\n",
    " x_{ij} &\\geq 0 \\quad \\text{ (cargo can't have negative weight)}\n",
    "\\end{align*}\n",
    "\n",
    " It is customary to write the objective function as a scalar product, $f(\\vct{x}) = \\ip{\\vct{c}}{\\vct{x}} := \\vct{c}^{\\trans}\\vct{x}$, and to express the constraints as systems of linear equations and inequalities using matrix-vector products,\n",
    "\n",
    "\\begin{align*}\n",
    "  \\maximize &\\ip{\\vct{c}}{\\vct{x}} \\\\\n",
    "  \\subjto &A\\vct{x}\\leq \\vct{b}\\\\\n",
    "  & B\\vct{x} = \\vct{d}\\\\\n",
    "          & \\vct{x}\\geq 0        \n",
    " \\end{align*}\n",
    "\n",
    "where the inequalities $\\geq$ and $\\leq$ are to be understood componentwise.\n",
    " This problem has a unique solution that can be found using CVXPY in Python.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define all the matrices and vectors involved\n",
    "c = np.array([300,300,350,350,270,270])\n",
    "A = np.array([[1, 1, 0, 0, 0, 0],\n",
    "              [0, 0, 1, 1, 0, 0],\n",
    "              [0, 0, 0, 0, 1, 1],\n",
    "              [1, 0, 1, 0, 1, 0],\n",
    "              [0, 1, 0, 1, 0, 1],\n",
    "              [8, 0, 10, 0, 7, 0],\n",
    "              [0, 8, 0, 10, 0, 7]])\n",
    "b = np.array([25,32,28,35,40,250,400]);\n",
    "B = np.array([1/35, -1/40, 1/35, -1/40, 1/35, -1/40]);\n",
    "d = np.zeros(1)\n",
    "\n",
    "# Create variables, objective and constraints\n",
    "x = Variable(6)\n",
    "constraints = [A*x <= b, B*x == d, x >= 0]\n",
    "objective = Maximize(c*x)\n",
    "\n",
    "# Create a problem using the objective and constraints and solve it\n",
    "prob = Problem(objective, constraints)\n",
    "prob.solve()\n",
    "\n",
    "print \"Solution found: \\n\", np.round(np.abs(x.value), decimals=2).transpose()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the solution found is\n",
    " \\begin{equation*}\n",
    " x_{11} = 6.75 , x_{12} =  7.71, x_{21} = 0, x_{22} = 32, x_{31} = 28, x_{32} = 0.\n",
    " \\end{equation*}\n",
    "\n",
    " We made some simplifying assumptions, for example that the cargo can be split up into arbitrary fractions. Additional work is required to resolve these issues.\n",
    " Problems of this kind are known as **linear programming**, because the objective function and the constraints are given by linear functions. Such problems can be solved efficiently using the simplex algorithm or interior point methods. The highly developed theory of linear programming acts as a template for more general convex optimization that is developed in this course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A third example: image inpainting</font>\n",
    "---\n",
    "Optimization methods play an increasingly important role in image and signal processing. An image can be viewed as an $m\\times n$ matrix $\\mtx{U}$, with each entry $u_{ij}$ corresponding to a light intensity (for greyscale images), or a colour vector, represented by a triple of red, green and blue intensities (usually with values between $0$ and $255$ each). For simplicity the following discussion assumes a greyscale image. For compututational pursposes, the matrix of an image is often viewed as an $mn$-dimensional vector $\\vct{u}$, with the columns of the matrix stacked on top of each other. \n",
    "\n",
    "In the **image inpainting** problem, one aims to *guess* the true value of missing or corrupted entries of an image. There are different approaches to this problem. A conceptually simple approach is to replace the image with the *closest* image among a set of images satisfying typical properties. But what are typical properties of a typical image? Some properties that come to mind are:\n",
    "\n",
    "* Images tend to have large homogeneous areas in which the colour doesn't change much;\n",
    "* Images have approximately low rank, when interpreted as matrices.\n",
    "\n",
    "Total variation image analysis takes advantage of the first property. The **total variation** or TV-norm is the sum of the norm of the horizontal and vertical differences,\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\|\\vct{U}\\|_{\\mathrm{TV}} = \\sum_{i=1}^m \\sum_{j=1}^n \\sqrt{(u_{i+1,j}-u_{i,j})^2+(u_{i,j+1}-u_{i,j})^2},\n",
    "\\end{equation*}\n",
    "\n",
    "where we set entries with out-of-bounds indices to $0$. The TV-norm naturally increases with increased variation or sharp edges in an image. Consider for example the two following matrices (imagine that they represent a $3\\times 3$ pixel block taken from an image).\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mtx{U}_1 = \\begin{pmatrix}\n",
    " 0 & 17 & 3 \\\\\n",
    " 7 & 32 & 0 \\\\\n",
    " 2 & 9 & 27\n",
    "\\end{pmatrix}, \\quad\n",
    "\\mtx{U}_2\\begin{pmatrix}\n",
    "1 & 1 & 3\\\\\n",
    "1 & 0 & 0\\\\\n",
    "0 & 0 & 2\n",
    "\\end{pmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "The left matrix has TV-norm $\\|\\mtx{U}_1\\|_{\\mathrm{TV}} = 200.637$, while the right one has TV-norm $\\|\\mtx{U}_2\\|_{\\mathrm{TV}} = 14.721$ (verify this!) Intuitively, we would expect a natural image with artifacts added to it to have a higher TV norm.\n",
    "\n",
    "Now let $\\mtx{U}$ be an image with entries $u_{ij}$, and let $\\Omega\\subset [m]\\times [n] = \\{(i,j) \\mid 1\\leq i\\leq m, 1\\leq j\\leq n\\}$ be the set of indices where the original image and the corrupted image coincide (all the other entries are missing). One could attempt to find the image with the *smallest* TV-norm that coincides with the knwon pixels $u_{ij}$ for $(i,j)\\in \\Omega$. This is an optimization problem of the form\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\minimize \\|\\vct{X}\\|_{\\mathrm{TV}} \\subjto x_{ij} = u_{ij} \\text{ for } (i,j) \\in \\Omega.\n",
    "\\end{equation*}\n",
    "\n",
    "The TV-norm is an example of a convex function and the constraints are linear conditions which define a convex set. This is again an example of a **convex optimization problem** and can be solved efficiently by a range of algorithms. For the time being we will not go into the algorithms but solve it using CVXPY. The example below is based on an example from the [CVXPY Tutorial](http://www.cvxpy.org/en/latest/tutorial/index.html), and it is recommended to look at this tutorial for other interesting examples! \n",
    "\n",
    "**Warning:** the example below uses some more advanced Python programming, it is not necessary to understand the details at this point. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our first piece of code below, we load the image and a version of the image with text written on it, and display the images. The **Python Image Library (PIL)** is used for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Load the images and convert to numpy arrays for processing.\n",
    "U = np.array(Image.open(\"images/alanturing.png\"))\n",
    "Ucorr = np.array(Image.open(\"images/alanturing-corr.png\"))\n",
    "\n",
    "# Display the images\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 2,figsize=(10, 5))\n",
    "\n",
    "ax[0].imshow(U);\n",
    "ax[0].set_title(\"Original Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(Ucorr);\n",
    "ax[1].set_title(\"Corrupted Image\")\n",
    "ax[1].axis('off');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After having the images at our disposal, we determine which entries of the corrupted image are known. We store these in a *mask* $M$, with entries $m_{ijk}=1$ if the colour $k$ of the $(i,j)$-th pixel is known, and $0$ otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Each image is now an m x n x 3 array, with each pixel represented\n",
    "# by three numbers between 0 and 255, corresponding to red, green and blue\n",
    "rows, cols, colours = U.shape\n",
    "\n",
    "# Create a mask: this is a matrix with a 1 if the corresponding \n",
    "# pixel is known, and zero else\n",
    "M = np.zeros((rows, cols, colours))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        for k in range(colours):\n",
    "            if U[i, j, k] == Ucorr[i, j, k]:\n",
    "                M[i, j, k] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to solve the optimization problem using CVXPY. As the problem is rather big ($400\\times 600\\times 3 = 720000$ variables), it is important to choose a good solver that will solve the problem to sufficient accuracy in an acceptable amount of time. For the example at hand, we choose the SCS solver, which can be specified when calling the **solve** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determine the variables and constraints\n",
    "variables = []\n",
    "constraints = []\n",
    "for k in range(colours):\n",
    "    X = Variable(rows, cols)\n",
    "    # Add variables\n",
    "    variables.append(X)\n",
    "    # Add constraints by multiplying the relevant variable matrix elementwise with the mask\n",
    "    constraints.append(mul_elemwise(M[:, :, k], X) == mul_elemwise(M[:, :, k], Ucorr[:, :, k]))\n",
    "\n",
    "# Create a problem instance with\n",
    "objective = Minimize(tv(variables[0],variables[1],variables[2]))\n",
    "\n",
    "# Create a problem instance and solve it using the SCS solver\n",
    "prob = Problem(objective, constraints)\n",
    "prob.solve(verbose=True, solver=SCS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we solved the optimization problem, we have a solution stored in 'variables'. We have to transform this back into an image and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Load variable values into a single array.\n",
    "Urec = np.zeros((rows, cols, colours), dtype=np.uint8)\n",
    "for i in range(colours):\n",
    "    Urec[:, :, i] = variables[i].value\n",
    "\n",
    "fig, ax = plt.subplots(1, 2,figsize=(10, 5))\n",
    "\n",
    "# Display the inpainted image.\n",
    "ax[0].imshow(Urec);\n",
    "ax[0].set_title(\"Inpainted Image\")\n",
    "ax[0].axis('off')\n",
    "\n",
    "ax[1].imshow(np.abs(Ucorr[:,:,0:3] - Urec));\n",
    "ax[1].set_title(\"Difference Image\")\n",
    "ax[1].axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Another typical structure of images is that the **singular values** of the image, considered as matrix, decay quickly. The **singular value decomposition** (SVD) of a matrix $\\mtx{A}\\in \\R^{m\\times n}$ is the matrix product\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\mtx{A} = \\mtx{U}\\mtx{\\Sigma}\\mtx{V}^{T},\n",
    "\\end{equation*}\n",
    "\n",
    "where $\\mtx{U}\\in \\R^{m\\times m}$ and $\\mtx{V}\\in \\R^{n\\times n}$ are orthogonal matrices, and $\\mtx{\\Sigma}\\in \\R^{m\\times n}$ is a diagonal matrix with entries $\\sigma_{1},\\dots,\\sigma_{\\mathrm{min}\\{m,n\\}}$ on the diagonal. Instead of minimizing the TV-norm of an image $\\mtx{X}$, one may instead try to minimize the **Schatten 1-norm**, defined as the sum of the singular values, $\\|\\vct{U}\\|_{S_1} = \\sigma_1+\\cdots+\\sigma_{\\mathrm{min}\\{m,n\\}}$. The problem is then\n",
    "\n",
    "\\begin{equation*}\n",
    "  \\minimize \\|\\vct{X}\\|_{S_1} \\subjto x_{ij} = u_{ij} \\text{ for } (i,j) \\in \\Omega.\n",
    "\\end{equation*}\n",
    "\n",
    "As we will see towards the end of the course, this is an instance of a type of convex optimization problem known as **semidefinite programming**. Luckily, CVXPY includes the Schatten 1-norm (also known as nuclear norm) as valid objective function, so we don't have to deal with the details of this problem. As the problem is computationally intensive, we just reproduce the result.\n",
    "\n",
    "![Nuclear norm inpainting](images/nucnorm-inpaint.png)\n",
    "\n",
    "In this example, the result appears worse as in the problem involving the TV-norm. Alternatively, one may also use the $1$-norm of the image applied to a discrete cosine transfrom (DCT) or a discrete wavelet transform (DWT).\n",
    "\n",
    "Of course, one could run the above examples for fun with different types of images in an attempt to get rid of certain parts. In the example below, we set a parrot free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from cvxpy import *\n",
    "\n",
    "# Load the images and convert to numpy arrays for processing.\n",
    "U = np.array(Image.open(\"images/test.png\"))\n",
    "Ucorr = np.array(Image.open(\"images/parrot-corr1.png\"))\n",
    "\n",
    "# Each image is now an m x n x 3 array\n",
    "rows, cols, colours = U.shape\n",
    "\n",
    "# Create a mask: this is a matrix with a 1 if the corresponding \n",
    "# pixel is known, and zero else\n",
    "M = np.zeros((rows, cols, colours))\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        for k in range(colours):\n",
    "            if U[i, j, k] == Ucorr[i, j, k]:\n",
    "                M[i, j, k] = 1\n",
    "                \n",
    "# Determine the variables and constraints\n",
    "variables = []\n",
    "constraints = []\n",
    "for k in range(colours):\n",
    "    X = Variable(rows, cols)\n",
    "    # Add variables\n",
    "    variables.append(X)\n",
    "    # Add constraints by multiplying the relevant variable matrix elementwise with the mask\n",
    "    constraints.append(mul_elemwise(M[:, :, k], X) == mul_elemwise(M[:, :, k], Ucorr[:, :, k]))\n",
    "\n",
    "# Create a problem instance with\n",
    "objective = Minimize(tv(variables[0],variables[1],variables[2]))\n",
    "\n",
    "# Create a problem instance and solve it using the SCS solver\n",
    "prob = Problem(objective, constraints)\n",
    "prob.solve(verbose=True, solver=SCS)\n",
    "\n",
    "# Load variable values into a single array.\n",
    "Urec = np.zeros((rows, cols, colours), dtype=np.uint8)\n",
    "for i in range(colours):\n",
    "    Urec[:, :, i] = variables[i].value\n",
    "\n",
    "# Display images\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1, 2,figsize=(10, 5))\n",
    "ax[0].imshow(U);\n",
    "ax[0].set_title(\"Caged parrot\")\n",
    "ax[0].axis('off')\n",
    "ax[1].imshow(np.abs(Urec));\n",
    "ax[1].set_title(\"Free parrot\")\n",
    "ax[1].axis('off');"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
